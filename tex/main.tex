\documentclass{article}
\usepackage{fullpage}
\usepackage{parskip}
\usepackage{standalone}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{xfrac}
\usepackage{enumitem}
\usepackage[table]{xcolor}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{calc}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{patterns,snakes}
\usetikzlibrary{decorations.text}
\usetikzlibrary{arrows.meta}


\newtheorem{prop}{Proposition}


\title{Modelling Queues Where Customers Randomly Change Priority Classes While Waiting}
\author{Geraint I. Palmer, Michalis Panayidis, Vincent Knight \& Elizabeth Williams}
\date{}

\begin{document}
\maketitle

\section{Introduction}
There are a number of situations in which a customer's priority in a queue might
change during their time queueing, or equivalently where their priority depends
on the amount of time they have already spent in the queue.
Classic examples arise in healthcare systems, for example when a patient's
medical urgency might increase the longer they spend waiting due to health
degeneration. Another example would be a prioritisation scheme that attempts a
trade-off between medical need and waiting times.
These are both examples where a patient's priority has the chance to upgrade
over time while in the queue.
However there also might be situations in which a patient's priority can
downgrade over time: consider a medical intervention that can improve a
patient's outcome if caught early, if a patient has been waiting a long time
already then they might be passed over for a newly referred patient who will
gain more benefit from the intervention. In this case a patient's priority is
downgraded the longer they wait.

In this paper a single $M/M/c$ queue is modelled, with multiple classes of
customer of different priorities. While waiting in the queue customers change
their class to any other class at specific rates. Thus upgrades, downgrades, and
`skip-grades' (moving to a priority class not immediately above or below the
current class) are modelled.

This is first modelled using simulation, where we describe generalisable logic.
This is implemented in version v2.3.0 of the Ciw library in Python
\cite{palmer19}.
Then two Markov chain models are defined for the system, which are used to find
steady state distributions and expected sojourn times for each customer class.
These Markov chains give some insights into the behaviour of the systems under
different combinations of parameters; and numerical experiments give further
behaviours.

This paper is structured as follows:
Section~\ref{sec:system} defines the system under consideration in detail.
Section~\ref{sec:related} highlights some previous and related work.
Section~\ref{sec:simulation} discusses the contribution to the Ciw library and
the logic required to simulate this system.
Section~\ref{sec:makovchains} defines two Markov chain models of the system, one
useful for considering system-wide statistics such as state probabilities, and
one useful for considering customers' statistics such as average sojourn time.
Section~\ref{sec:bound} explores a bounded approximation for numerically
tractable analysis, and gives guidelines on choosing a large enough bound so as
to sufficiently approximate an unbounded system.
Section~\ref{sec:stationary} explores the existence or otherwise of systems that
can reach steady state.
Section~\ref{sec:behaviour} presents results from numerical experiments that
give insight into the behaviour of the system under various parameters.
Section~\ref{sec:validation} experimentally justifies the use of these models
to model scenarios where prioritisation rules are unknown.





\section{System Under Consideration}\label{sec:system}
Consider an $M/M/c$ queue with $K$ classes of customer labelled
$0, 1, 2, \dots, K-1$.
Let:

\begin{itemize}
  \item $\lambda_k$ be the arrival rate of customers of class $k$,
  \item $\mu_k$ be the service rate of customers of class $k$,
  \item $\theta_{i,j}$ be the rate at which customers of class $i$ change
  to customers of class $j$ while they are waiting in line.
\end{itemize}

Customers of class $i$ have priority over customers of class $j$ if $i < j$.
Customers of the same class are served in the order they arrived to that class.

Figure~\ref{fig:twoclass_example} shows an example with two classes of customer.

\begin{figure}
\begin{center}
\includestandalone[width=0.7\textwidth]{img/priority_queue}
\end{center}
\caption{An example of a two-class priority queue.}
\label{fig:twoclass_example}
\end{figure}

The key feature here is the $K \times K$ class change matrix
$\Theta = (\theta_{i,j})$. All elements $\theta_{i,j}$ where $i \neq j$ are
rates, and so are non-negative real numbers, if customers of class $i$ cannot
change to customers of class $j$ directly, then $\theta_{i,j} = 0$. The diagonal
values $\theta_{i,i}$ are unused as customers cannot change to their own class.
All elements $\theta_{i,i-1}$ represent the direct upgrade rates; all elements
$\theta_{i,i+1}$ represent the direct downgrade rates, while all other elements
can be thought of as `skip-grades`.
This is shown in Figure~\ref{fig:skipgrades}.

\begin{figure}
\begin{center}
\includestandalone[width=0.65\textwidth]{img/skipgrades}
\end{center}
\caption{Representations of parts of the matrix $\Theta$. Example when $K=5$.}
\label{fig:skipgrades}
\end{figure}




\section{Related Work}\label{sec:related}
Systems of this kind have been investigated previously:

\begin{itemize}
  \item \cite{jackson60} (1960): Non preemptive M/M/1 where customers
      are served in order of the difference between their waiting time
        and urgency number (that is priorities increasing linearly over
        time). Solved by considering event probabilities at clock ticks.
  \item \cite{kleinrock164} (1964): Another formulation giving the same
      behaviour as \cite{jackson60}, but now for both non preemptive and
        preemptive priorities, and multiple customer classes. Called `delay
        dependent' or `time dependant' priorities, and recently by
        `accumulating' priorities.
  \item \cite{holtzman71} (1971): Similar to \cite{jackson60}, but treat each
      urgency number as a separate customer class, and not considering
        clock ticks. Upper and lower bounds on the waiting times, based
        on FIFO and static priorities.
  \item \cite{netterman79} (1979): Now considers the case where
      priorities increase non-linearly but concavely over time.
  \item \cite{fratini90} (1990): Non preemptive M/G/1 queue with two
      classes of customers, where priorities switch if the number from
        one class exceeds a given threshold. Lower priority customers
        have a finite waiting capacity, higher have infinite capacity.
  \item \cite{vanmieghan95} (1995): Introduces the generalised $c\mu$-rule
    (first conceived in \cite{smith56}), which applies a class- and waiting
      time-dependant cost to each customer. This acts as a scheduling rule,
      but can also model dynamic priorities amongst customers.
  \item \cite{knessl03} (2003): Similar to \cite{fratini90} but with Markovian
      services and infinite waiting capacities for both customers.
  \item \cite{xie08} (2008): Preemptive n-priority-classes M/M/c with
      exponential upgrades. Customers only upgrade to the priority
        immediately higher than themselves. Stability considered.
  \item \cite{down10} (2010): Preemptive two-priority-classes M/M/c with
      exponential upgrades. Customers cannot upgrade if the number of
        lower priority customers is below a given threshold. Holding
        costs considered.
  \item \cite{he12} (2012): Extension of \cite{down10}, allows batch
      arrivals, multiple classes, phase-type upgrades and services.
        Customers only upgrade to the priority immediately higher than
        themselves.
  \item \cite{stanford14} (2014): Furthers the work of \cite{kleinrock164} to
      look at the maximum priority of the waiting customers in a single server
        queue as a stochastic process. This is extended in \cite{sharif14} to
        multi-server queues.
  \item \cite{klimenok20} (2020): Upgrades and downgrades after a random,
      exponentially distributed, amount of time. Models two priority classes
        in a single server, finite buffer system with batch arrivals. Extended
        in \cite{dudin21} to include unreliable services and impatient
        customers. 
  \item \cite{bilodeau22} (2022): Analytical (truncated) expressions for
      a two class delayed accumulating priority M/G/1 queue. Customer
        priorities increase linearly over time, at different rates
        according to class, after an initial fixed delay.
\end{itemize}


\begin{itemize}
  \item \cite{ding19} (2019): Evidence that in Canada that decision makers
      often use their own discretion in deciding which patients to be seen,
        rather than FIFO within each triage category. Fits prioritisation rules
        to this discretionary behaviour.
\end{itemize}


\section{Simulation Model Logic}\label{sec:simulation}
The Ciw library \cite{palmer19} is an open-source Python library for
discrete-event simulation of open queueing networks. A key contribution of this
work is the adaptation of the library's logic to facilitate the type of
dynamically changing priority classes described in Section~\ref{sec:system}.
This adaptation is released in version Ciw v2.3.0, with usage documentation at
\url{https://ciw.readthedocs.io/en/latest/Guides/change-class-while-queueing.html}.

The core of Ciw's logic is the event scheduling approach, described in
\cite{robinson14}. This is a variant of the three-phase approach, with an
\textbf{A}-phase which advances the clock to the next scheduled event, a
\textbf{B}-phase where scheduled events are carried out, and a \textbf{C}-phase
where conditional events are carried out. Figure~\ref{fig:eventscheduling} shows
a flow diagram of the logic of the event scheduling approach.

\begin{figure}
    \centering
    \includestandalone[width=\textwidth]{img/eventschedulingapproach}
    \caption{Flow diagram of the event scheduling approach used by Ciw, adapted from \cite{palmer18}.}
    \label{fig:eventscheduling}
\end{figure}

The primary scheduled, or \textbf{B}-events are customers arriving to a queue,
and customers finishing service. The conditional, or \textbf{C}-events are those
that happen immediately after, and because of, these \textbf{B}-events. The
primary ones are customers beginning service, and customers leaving the queue.

All other features of queueing systems that can be simulated with the Ciw
library involve increasing the range of \textbf{B}- and \textbf{C}-events that
can happen during the simulation run.
In the case of customers randomly changing priority classes while waiting, one
additional \textbf{B}-event and one additional \textbf{C}-event are included:

\begin{itemize}
  \item Upon arrival to the queue customers are assigned a date in which they
  will change customer class, determined by randomly sampling from a
  distribution. Therefore each customer's event of changing customer class is
  scheduled for the future, and are therefore \textbf{B}-events. If those
  customers begin service (which might not be scheduled yet) before that event
  has occurred, then their changing customer class event is cancelled.
  \item Upon changing class, they immediately schedule another changing class
  event for the future, again sampling a date from a given distribution. This
  happens immediately after the above, and so is a \textbf{C}-event.
\end{itemize}

Note that the particular distributions used to sample class change dates in
these cases are generic, and any of Ciw's currently pre-programmed distributions
can be chosen, or custom distributions can also be input. For the systems
described in this paper, we choose Exponential distributions with rates
determined by the class change matrix $\Theta$.




\section{Markov Chain Models}\label{sec:makovchains}
The situation described in words in Section~\ref{sec:system} can be described
precisely as two different Markov chains.
The first, described in Section~\ref{sec:state_formulation}, describes the
overall changes in state, where a state records the number of customers of each
class at the node. This is useful for analysing system-wide statistics such as
average queue size.
The second, described in Section~\ref{sec:sojourn_formulation}, describes how an
individual arriving customer experiences the system until their exit. This is
useful for analysing individual customers' statistics such as average sojourn
time.


\subsection{Discrete State Markov Chain Formulation}\label{sec:state_formulation}
Let
$\underline{\mathbf{s}}_t = (s_{0,t}, s_{1,t}, \dots, s_{K-1,t}) \in \mathbb{N}^K$
represent the state of the system at time step $t$, where $s_{k,t}$ represents
the number of customers of class $k$ present at time step $t$. Let $S$ denote
set of all states $\underline{\mathbf{s}}_t$. 

The rates of change between $\underline{\mathbf{s}}_t$ and
$\underline{\mathbf{s}}_{t+1}$ are given by Equation~\ref{eqn:transitions},
where $\underline{\mathbf{\delta}} = \underline{\mathbf{s}}_{t+1} - \underline{\mathbf{s}}_t$,

\begin{equation}\label{eqn:transitions}
q_{\underline{\mathbf{s}}_t, \underline{\mathbf{s}}_{t+1}} = 
\begin{cases}
\lambda_k & \text{if } \delta_k = 1 \text{ and } \delta_i = 0 \; \forall \; i \neq k \\
B_{k,t} \mu_k & \text{if } \delta_k = 1 \text{ and } \delta_i = 0 \; \forall \; i \neq k \text{ and } \sum_{i < k} s_{i,t} < c \\
(s_{k,t} - B_{k,t}) \theta_{k_0,k_1} & \text{if } \delta_{k_0} = -1 \text{ and } \delta_{k_1} = 1 \text{ and } \delta_i = 0 \; \forall \; i \neq k_0, k_1 \\
0 & \text{otherwise.}
\end{cases}
\end{equation}

and $B_{k,t}$, representing the number of customers of class $k$ currently in
service at time step $t$, is given by Equation~\ref{eqn:inservice}, where $c$
is the number of servers.

\begin{equation}\label{eqn:inservice}
B_{k,t} =\min\left(c - \min\left(\sum_{i < k} s_{i,t}, c\right), s_{k,t}\right)
\end{equation}

Let $\pi_{\underline{\mathbf{s}}}$ denote the steady state probability of being
in state $\underline{\mathbf{s}} \in S$.



\subsection{Sojourn Time Markov Chain Formulation}\label{sec:sojourn_formulation}
Let $\underline{\mathbf{z}}_t = (z_{0,t}, z_{1,t}, \dots, z_{n,t} \dots, z_{K-1,t}, m_t, n_t) \in \mathbb{N}^{K+2} \times (1, \dots, K - 1)$
represent the state of a particular customer at time step $t$, where $n_t$
represents that customer's class at time $t$; $z_{k,t} \; \forall \; k < n$
represents the number of customers of class $k$ in front of the customer in the
queue at time $t$; $z_{k,t} \; \forall \; n < k < K$ represents the number of
customers of class $k$ behind the customer in the queue at time $t$; and $m_t$
represent the number of customers of class $n_t$ behind the customer in the
queue at time $t$.
Also let $\star$ represent an absorbing state, representing the state where that
customer has finished service and left the system.
Let $Z$ denote set of all states $\underline{\mathbf{z}}_t$ and $\star$. 


Then the rates of change between $\underline{\mathbf{z}}_t$ and
$\underline{\mathbf{z}}_{t+1}$ are given by Equation~\ref{eqn:transitions_sojourn},
where $\underline{\mathbf{\delta}} = \underline{\mathbf{z}}_{t+1} - \underline{\mathbf{z}}_t$,

\begin{equation}\label{eqn:transitions_sojourn}
\resizebox{\textwidth}{!}{%
$q_{\underline{\mathbf{z}}_t, \underline{\mathbf{z}}_{t+1}} = 
\begin{cases}
\mu_n & \text{if } z_{t+1} = \star \text{ and } \sum_{k \leq n} z_{k, t} < c \\
\lambda_n & \text{if } \delta_K = 1 \text{ and } \delta_i = 0 \; \forall \; i \neq K \\
\lambda_k & \text{if } \delta_k = 1 \text{ and } \delta_i = 0 \; \forall \; i \neq k \text{ and } k \neq n\\
A_{k,n,t} \mu_k & \text{if } \delta_k = -1 \text{ and } \delta_i = 0 \; \forall \; i \neq k \text{ and } k < K\\
\tilde{A}_{n,t} \mu_n & \text{if } \delta_K = -1 \text{ and } \delta_i = 0 \; \forall \; i \neq K\\
(z_{k_0,t} - A_{k_0,n,t}) \theta_{k_0,k_1} & \text{if } \delta_{k_0} = -1 \text{ and } \delta_{k_1} = 1 \text{ and } \delta_i = 0 \; \forall \; i \neq k_0, k_1 \text{ and } k_0 < K \text{ and } k_1 \neq n, K, K+1 \\
(z_{K,t} - \tilde{A}_{n,t}) \theta_{n,k} & \text{if } \delta_K = -1 \text{ and } \delta_{k} = 1 \text{ and } \delta_i = 0 \; \forall \; i \neq k, n \text{ and } k < K \\
(z_{k,t} - A_{k,n,t}) \theta_{k,n} & \text{if } \delta_k = -1 \text{ and } \delta_K = 1 \text{ and } \delta_i = 0 \; \forall \; i \neq k, K \\
\theta_{n, k} & \text{if } \delta_n = z_{K,t} \text{ and } \delta_K = -z_{K,t} \text{ and } \delta_{K+1} = n - k \text{ and } \delta_i = 0 \text{ otherwise, and } \sum_{k \leq n} z_{k, t} < c \\
0 & \text{otherwise.}
\end{cases}$%
}
\end{equation}

and $A_{k,n,t}$ and $\tilde{A}_{n, t}$, representing the number of customers of
class $k$ currently in service, are given by Equations~\ref{eqn:inservice_adapt}
and~\ref{eqn:inservice_adapt_tilde}.

\begin{equation}\label{eqn:inservice_adapt}
A_{k,n,t} =
\begin{cases}
\min\left(c, \sum_{i \leq k} z_{i,t}\right) - \min\left(c \sum_{i < k} z_{i,t}\right) & \text{if } k \leq n \\
\min\left(c, \sum_{i \leq k} z_{i,t} + 1 + z_{K,t}\right) - \min\left(c \sum_{i < k} z_{i,t} + 1 + z_{K,t}\right) & \text{if } n < k < K
\end{cases}
\end{equation}

\begin{equation}\label{eqn:inservice_adapt_tilde}
\tilde{A}_{n,t} =
\min\left(c, \sum_{i \leq n} z_{i,t} + 1 + z_{K,t}\right) - \min\left(c, \sum_{i \leq n} z_{i,t} + 1\right) \\
\end{equation}

Let $a_{\underline{\mathbf{z}}}$ denote the expected time to absorption
from state $\underline{\mathbf{z}} \in Z$.


\subsubsection{Mean sojourn time calculation}\label{sec:meansojourncalc}
The expected time to absorption can be calculated from each state.
Customers arrive in all states where $z_K = 0$, and their class can be
determined by $n$. First define
$\tilde{Z} = \{\underline{\mathbf{z}} \in Z\setminus\{\star\} \; | \; z_K = m = 0\} \subset Z$
as the set of all states where the newly arriving customer can can arrive.
Let $c: \tilde{Z} \rightarrow S$ be a map between states in $\tilde{Z}$ and $S$,
given in Equation~\ref{eqn:map_state}.

\begin{equation}\label{eqn:map_state}
c\left(\underline{\mathbf{z}} = (z_0, z_1, \dots, z_{K-1}, m, n) \right) = (z_0, z_1, \dots, z_{K-1})
\end{equation}

Note that $c$ is a surjective map, but not injective. In fact, for every element
$\underline{\mathbf{s}} \in S$ exactly $K$ states in $\tilde{Z}$ map to it.
These correspond to states at which each of the $K$ classes of customer can
arrive. In each of these states, the probability of a customer from class $k$
arriving is $\frac{\lambda_k}{\sum_{i=0}^{K-1} \lambda_i}$. Therefore, we can
combine this to get the overall mean sojourn time in
Equation~\ref{eqn:mean_sojourn}:

\begin{equation}\label{eqn:mean_sojourn}
\overline{\Psi} = \sum_{\underline{\mathbf{z}} \in \tilde{Z}} \sum_{k=0}^{K-1} \frac{\lambda_k}{\sum_{i=0}^{K-1} \lambda_i} \pi_{c(\underline{\mathbf{z}})} a_{\underline{\mathbf{z}}}
\end{equation}

Defining $\tilde{Z}_k = \{\underline{\mathbf{z}} \in \tilde{Z} \; | \; z_{K-1} = n = k\} \subset Z$
as the states that customers of class $k$ arrive to, the mean sojourn times for
customers who arrive as a given customer class $k$ is given by
Equation~\ref{eqn:mean_sojourn_class_k}.

\begin{equation}\label{eqn:mean_sojourn_class_k}
\Psi_k = \sum_{\underline{\mathbf{z}} \in \tilde{Z}_k} \pi_{c(\underline{\mathbf{z}})} a_{\underline{\mathbf{z}}}
\end{equation}



\section{Bounded Approximation}\label{sec:bound}
In order to analyse the above Markov chain models numerically, finite
approximations can be made. Let $b \in \mathbb{N}$, and define the $b$-bounded
version of the infinite queueing system described in Section~\ref{sec:system},
such that the maximum allowed number of customers of each priority class is $b$,
and customer losses when that number is exceeded. The equivalent $b$-bounded
Markov chains associated with this system are identical to those described in
Sections~\ref{sec:state_formulation} and~\ref{sec:sojourn_formulation} except
with bounded state spaces
$\underline{\mathbf{s}}_t = (s_{0,t}, s_{1,t}, \dots, s_{K-1,t}) \in (0, 1, \dots, b)^K$ and
$\underline{\mathbf{z}}_t = (z_{0,t}, z_{1,t}, \dots, z_{n,t} \dots, z_{K-1,t}, m_t, n_t) \in (0, 1, \dots, b)^{K+2}$
respectively. These Markov chains are finite and so stationary.

If the unbounded system is stationary, that is the system reaches steady state
and has steady state probabilities $\underline{\pi}$, then the steady states of
the $b$-bounded system, $\underline{\tilde{\pi}}$ is an approximation of
$\underline{\pi}$. As $b$ increases the probability of the number of
customers of a particular customer class in the unbounded system exceeding $b$
approaches zero as $b$ increases. Therefore as $b$ increases the $b$-bounded
system becomes a better and better approximation of the unbounded system.

Choosing an appropriate value for $b$ is a trade off between accuracy and model
size, and so computational time. An inefficient way to choose $b$ would be to
sequentially build bounded models, increasing $b$ each time, calculating the
statistics of interest, and observing when the relationship between $b$ and that
statistic levels off.
It would be more efficient to choose a $b$ and be able to immediately measure if
the accuracy is sufficient. We propose two measures, one for ergodic Markov
chains (the model in Section~\ref{sec:state_formulation}), and one for absorbing
Markov chains (the model in Section~\ref{sec:sojourn_formulation}).


\subsection{Accuracy measure for the ergodic Markov chain}\label{sec:ergodic_check}
Let $S_b = \{\underline{\mathbf{s}} \in S \;|\; b \in \underline{\mathbf{s}}\}$,
the set of states that lie on the Markov chain boundary. We wish to choose $b$
large enough that the boundary is irrelevant, that is that the Markov chain
hardly ever reaches the boundary. Therefore we propose the \textit{relative}
probability of being at the boundary, $\mathcal{Q}(b)$, to be a measure of
accuracy; if this is sufficiently small, then the bound $b$ is large enough.
This is given in Equation~\ref{eqn:relative_probability_boundary}, it is the
ratio of the probability of being at the boundary in the $b$-bounded system, and
the probability of being at the boundary if every state was equally likely. This
is necessary as the larger $b$ is, the larger the state space is, meaning that
the steady state probabilities are spread over more states and so are not
comparable alone, whereas the relative probability of being at the boundary is
comparable over different sizes of $b$.

\begin{equation}\label{eqn:relative_probability_boundary}
\mathcal{Q}(b) = \frac{|S|}{|S_b|} \sum_{s \in S_b} \tilde{\pi}_s
\end{equation}

To demonstrate the effect of $b$ on $\mathcal{Q}(b)$ under different systems,
consider the dynamic classes system with two customer classes,
$\lambda_1 = \frac{1}{2}$, $\lambda_2 = \frac{1}{2}$, $c = 1$,
$\mu_1 = \frac{1}{\rho}$, $\mu_2 = \frac{1}{\rho}$, $\theta_{12} = 1$, and
$\theta_{21} = 1$; where $0 < \rho < 1$ is some given traffic intensity.
Figure~\ref{fig:ergodic_check} shows the effect of $b$ on $\mathcal{Q}(b)$ for
this system, for different values of $\rho$. In all cases as $b$ increases,
$\mathcal{Q}(b)$ decreases, indicating greater accuracy of the bounded system.
As expected, as $\rho$ increases, we expect more customers in the queue, and so
the boundary $b$ needs to be much larger before it can be considered irrelevant.

\begin{figure}[!htbp]
  \begin{center}
    \includegraphics[width=0.6\textwidth]{img/quotient_check.pdf}
  \end{center}
  \caption{Demonstration of the effect of $b$ on $\mathcal{Q}(b)$}
  \label{fig:ergodic_check}
\end{figure}




\subsection{Accuracy measure for the absorbing Markov chain}\label{sec:absorbing_check}
The above check isn't possible for absorbing Markov chains as they will not
reach steady state, so another check is required. Define $h_{i,J}$ as
the hitting probabilities of a set of states $J$ from state $i$, that is, what
is the probability of ever reaching any state in $J$ when starting from state
$i$. These are defined recursively by Equation~\ref{eqn:hitting_probs}.

\begin{equation}\label{eqn:hitting_probs}
h_{iJ} = \begin{cases}
\sum_k p_{ik} h_{kJ} & \text{if } i \notin J \\
1 & \text{if } i \in J
\end{cases}
\end{equation}

Relating this to the absorbing Markov chain described in
Section~\ref{sec:sojourn_formulation}, and letting $Z_b \subset Z$ be the set of
boundary states such that
$Z_b = \{\underline{\mathbf{z}} \in Z \; | \; b \in \underline{\mathbf{z}}\}$,
then if a customer arrives to state $i$, the probability of that customer's
state reaching the boundary is $h_{iS_b}$. Therefore we propose the probability
of an arriving customer hitting the boundary, $\mathcal{P}(b)$, to be a measure
of accuracy; if this is sufficiently small, then the bound $b$ is large enough.
This is calculated in a similar way to the mean sojourn time in
Section~\ref{sec:meansojourncalc}, and given in Equation~\ref{eqn:hitting_measure}.

\begin{equation}\label{eqn:hitting_measure}
\mathcal{P}(b) = \sum_{\underline{\mathbf{z}} \in \tilde{Z}} \sum_{k=0}^{K-1} \frac{\lambda_k}{\sum_{i=0}^{K-1} \lambda_i} \pi_{c(\underline{\mathbf{z}})} h_{\underline{\mathbf{z}}, Z_b}
\end{equation}

To demonstrate the effect of $b$ on $\mathcal{P}(b)$ under different system,
consider the same dynamic classes system with two customer classes used in the
previous demonstration. Figure~\ref{fig:hitting_measure} shows the effect of $b$
on $\mathcal{P}(b)$ for this system, for different values of $\rho$. Again, in
all cases as $b$ increases, $\mathcal{P}(b)$ decreases, indicating greater
accuracy of the bounded system; and similarly as $\rho$ increases the boundary
$b$ needs to be larger before it can be considered irrelevant.

\begin{figure}[!htbp]
  \begin{center}
    \includegraphics[width=0.6\textwidth]{img/hitting_check.pdf}
  \end{center}
  \caption{Demonstration of the effect of $b$ on $\mathcal{P}(b)$}
  \label{fig:hitting_measure}
\end{figure}






\section{Existence of Stationary Distributions}\label{sec:stationary}
It is useful to know whether a dynamic classes system is stationary, that is,
will it reach steady state or not. Proposition~\ref{thrm:steadystate} gives a
naive check for the existence or non-existence of steady states, but does not
cover all possibilities.

\begin{prop}\label{thrm:steadystate}
For an $M/M/c$ work conserving queue with $K$ classes of customer, with arrival
rate and service rate $\lambda_k$ and  $\mu_k$ for customers of class $k$,
respectively; then
\begin{enumerate}
  \item it will reach steady state if
  $\rho_{\max} = \frac{\sum_i \lambda_i}{c \min_i \mu_i} < 1$,
  \item it will never reach steady state if
  $\rho_{\min} = \frac{\sum_i \lambda_i}{c \max_i \mu_i} \geq 1$.
\end{enumerate}
\end{prop}

Note that this result does not assume any particular service discipline such as
first-in-first-out or prioritised classes, but holds for any work conserving
discipline.

\begin{proof}
The queue will reach steady state if the rate at which customers are added to
the queue is less than the rate at which customers leave the queue.
As arrivals are not state dependent, customers are added to the queue at a rate
$\sum_i \lambda_i$ when in any state.
The rate at which customers leave the queue is state dependent, depending on the
service discipline.

We do not need to consider cases when there are less than $c$ customers present,
as here any new arrival will increase the rate at which customers leave the
queue, as that arrival would enter service immediately.
Considering the cases where there are $c$ or more customers in the queue, there
are two extreme cases, either:

\begin{enumerate}
  \item all customers in service are of the class with the slowest service rate.
  In this case the rate at which customers leave the queue is $c \min_i \mu_i$,
  which is the slowest possible rate at which customers can leave the queue.
  If $\sum_i \lambda_i < c \min_i \mu_i$ then the rate at which customers enter
  the queue is smaller than the smallest possible rate at which customers leave
  the queue, and so will always be smaller than the rate at which customers
  leave the queue in all states. Therefore the system will reach steady state.
  Or:
  \item all customers in service are of the class with the fastest service rate.
  In this case the rate at which customers leave the queue is $c \max_i \mu_i$,
  which is the fastest possible rate at which customers can leave the queue.
  If $\sum_i \lambda_i \geq c \max_i \mu_i$ then the rate at which customers
  enter the queue is greater than or equal to the largest possible rate at which
  customers leave the queue, and so will always be greater or equal to than the
  rate at which customers leave the queue in all states. Therefore the system
  cannot reach steady state.
\end{enumerate}
\end{proof}

If $c \min_i \mu_i \leq \sum_i \lambda_i < c \max_i \mu_i$ then more
investigation is needed. In the case of dynamic priority classes the class
change matrix $\Theta$ may be significant. For example the service rate of
customers of one class may be very slow, however if the rate at which customers
leave that class is sufficiently large then that service rate may not have an
effect. Alternatively if the rate at which customers of the other classes change
to that class is large, then that slow service rate could be a bottleneck for
the system.

We can however approximately test if a system is stationary or not using
simulation. Consider the time series $x(t)$, representing the total number of
customers in the system at time $t$. In Ciw, this can be empirically recorded
using a state tracker object. If the system reaches steady state, then the
$x(t)$ will be stochastic with non-increasing trend, therefore it would be a
stationary time series. Conversely, if the system does not reach steady state,
then $x(t)$ will be stochastic with increasing trend, therefore it would be a
non-stationary time series.
The Augmented Dicky-Fuller (ADF) test \cite{dickyfuller79} tests for the
non-stationarity of a stochastic time series, and so can be utilised here to
test if a simulation has reached steady state or not. Note here that the time
series $x(t)$ recorded by Ciw has irregular gaps (time stamps are the discrete
time points where a customer arrives or leaves the system), and the ADF test
requires regularly spaced time stamps; therefore the Traces library
\cite{traces} is used to take regularly-spaced moving averages before the
hypothesis test is undertaken.

To demonstrate this, consider two examples:

\begin{itemize}
  \item Example 1, that is guaranteed to reach steady state by
  Proposition~\ref{thrm:steadystate}: $\lambda_1 = 2$, $\lambda_2 = 1$,
  $\mu_1 = 4$, $\mu_2 = 4$, $\theta_{12} = 1$, $\theta_{21} = 1$, $c = 1$;
  \item Example 2, that is guaranteed not to reach steady state by
  Proposition~\ref{thrm:steadystate}: $\lambda_1 = 2$, $\lambda_2 = 1$,
  $\mu_1 = 1$, $\mu_2 = 1$, $\theta_{12} = 1$, $\theta_{21} = 1$, $c = 2$.
\end{itemize}

\begin{figure}[!htbp]
  \begin{center}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{img/adf_test_steadystate.pdf}
    \caption{State time series for Example 1.}
    \label{fig:timeseries1}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{img/adf_test_not_steadystate.pdf}
    \caption{State time series for Example 2.}
    \label{fig:timeseries2}
  \end{subfigure}
  \end{center}
\end{figure}


Figures~\ref{fig:timeseries1} and~\ref{fig:timeseries2} shows their state time
series' $x(t)$ respectively. It is clear that the state time series for
Example~1 is stationary, and the state time series for Example~2 is
non-stationary and increasing. When performing the ADF test on these, Example~1
gives a p-value of 0.0004, rejecting the null hypothesis that the time series is
non-stationary, while Example 2 gives a p-value of 0.9961, and the null
hypothesis cannot be rejected.

There is a gap in Proposition~\ref{thrm:steadystate} for systems where
$c \min_i \mu_i \leq \sum_i \lambda_i < c \max_i \mu_i$. This is where the
dynamic priority classes can influence the stationarity of the system. Consider
a two class system with $\lambda_1 = 2$, $\lambda_2 = 2$, $c = 1$. For the
service rates of each customer class, consider two cases:

\begin{itemize}
  \item $\mu_1 = 3$ and $\mu_2 = 5$: here $\rho_{\text{max}} > 1$ and
  $\rho_{\text{min}} < 1$, and the prioritised class receive a slower
  service rate;
  \item $\mu_1 = 5$ and $\mu_2 = 3$: here $\rho_{\text{max}} > 1$ and
  $\rho_{\text{min}} < 1$, and the prioritised class receive a faster
  service rate.
\end{itemize}

In each of these cases, we can consider three other cases pertaining to the
class change rate matrix $\Theta$:

\begin{itemize}
  \item $\theta_{12} = 1$ and $\theta_{21} = 0$: downgrades but no upgrades;
  \item $\theta_{12} = 1$ and $\theta_{21} = 1$: bother downgrades and upgrades;
  \item $\theta_{12} = 0$ and $\theta_{21} = 1$: upgrades but no upgrades.
\end{itemize}

All these cases are not covered by Proposition~\ref{thrm:steadystate}, so we
experimentally investigate their stationarity using the Ciw simulation and ADF
test. Figure~\ref{fig:adf_gap} shows the results. Here we see that three of the
six cases are stationary, (a), (e), and (f), while the others are not. In all
three we see that there is possibility of a customer from the class with the
slower service rate transitioning to a class with the quicker service rate. In
two of the non-stationary cases, (c) and (d), customers with the slower service
rate have no possibility of transitioning out of their class, and so the queue
builds up indefinitely.
It is interesting to compare cases (b) and (e), in which both customer classes
can transition to the other customer class. Here one case is stationary, and the
other is non-stationary, with the only difference being whether the prioritised
class has the quicker service rate or not. This evidences the interesting
interplay between service rate, priority class, and class change rates.

\begin{figure}[!htbp]
  \begin{center}
    \includegraphics[width=\textwidth]{img/adf_theorem_gap.pdf}
    \caption{Investigating the stationarity under six cases not covered by
    Proposition~\ref{thrm:steadystate}.}
    \label{fig:adf_gap}
  \end{center}
\end{figure}


\section{Effect of $\Theta$ on Customer Experience}\label{sec:behaviour}
In order to explore the effect that the parameters have on system behaviour and
customer experience, numerical experiments we run.
Table~\ref{tbl:parameter_sweep} gives the ranges of value for which simulation
experiments were run. These experiments will be used to explore the models in
the next subsections. For these simulations, upgraded individuals pre-empt
individuals of a less prioritised class, and these pre-empted individuals have
their service time re-sampled.

\begin{table}
\begin{center}
\begin{tabular}{ll}
\toprule
Parameters & Values \\
\midrule
$\Lambda_1$ & $1$ \\
$\Lambda_2$ & $\sfrac{1}{2}$, $\sfrac{2}{3}$, $1$, $\sfrac{3}{2}$, $2$ \\
$\mu_1$ & $\sfrac{1}{2}$, $1$, $2$, $3$, $4$ \\
$\mu_2$ & $\sfrac{1}{2}$, $1$, $2$, $3$, $4$ \\
$\theta_{12}$ & $\sfrac{1}{2}$, $\sfrac{2}{3}$, $1$, $\sfrac{3}{2}$, $2$ \\
$\theta_{21}$ & $\sfrac{1}{2}$, $\sfrac{2}{3}$, $1$, $\sfrac{3}{2}$, $2$ \\
$c$ & $1$, $2$, $3$ \\
\bottomrule
\end{tabular}
\caption{Table of parameters explored, for two classes of customer. Simulations
         were run for $5000$ time units, with a warm-up time of $200$ and cool
         down time of $200$ time units.}
\label{tbl:parameter_sweep}
\end{center}
\end{table}

Figure~\ref{fig:theta_effect} shows the effect of $\Theta$ on the number of
customers and sojourn times, broken down by customer class. For each
$\theta_{12}$, $\theta_{21}$ pair, the plots show the average number of
customers and average sojourn time obtained over all the experiments in the
parameter sweep where $\rho_{\max} < 1$, that is those that reach steady state.
We see that as $\theta_{21}$ increases, and $\theta_{12}$ decreases, that is
more customers are being upgraded than downgraded, then:

{
\renewcommand{\theenumi}{E\arabic{enumi}}
\begin{enumerate}
  \item \label{enm:custs_1over2} the number of Class 1 customers present increases,
  \item \label{enm:custs_2over1} the number of Class 2 customers present decreases,
  \item \label{enm:custs_pronounced} this effect is more pronounced for customers of Class 1 than Class 2;
  \item \label{enm:sojourn_1over2} the sojourn time of Class 1 customers increases,
  \item \label{enm:sojourn_2over1} the sojourn time of Class 2 customers decreases,
  \item \label{enm:sojourn_pronounced} this effect is more pronounced for customers of Class 2 than Class 1;
\end{enumerate}

also, as $\theta_{21}$ increases, independent of $\theta_{12}$

\begin{enumerate}[resume]
  \item \label{enm:custs} the overall number of customers present increases.
\end{enumerate}
}

\begin{figure}[!htbp]
  \begin{subfigure}[b]{\textwidth}
    \begin{center}
    \includegraphics[width=\textwidth]{img/theta_effect_cust_numbers.pdf}
    \end{center}
    \caption{Effect of $\Theta$ on customer numbers.}
    \label{fig:theta_effect_custs}
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \begin{center}
    \includegraphics[width=0.666\textwidth]{img/theta_effect_sojourn_times.pdf}
    \end{center}
    \caption{Effect of $\Theta$ on sojourn times.}
    \label{fig:theta_effect_sojourn}
  \end{subfigure}
  \caption{Effect of $\Theta$ on customer experience.}
  \label{fig:theta_effect}
\end{figure}

Effects~\ref{enm:custs_1over2} and~\ref{enm:custs_2over1} come directly from the
fact that increasing $\theta_{21}$ and decreasing $\theta_{12}$ upgrades more
customers than are downgraded. Effect~\ref{enm:custs} is explained by the
pre-emption: when an interrupted individual restarts service their service time
is re-sampled, causing more work for the system and causing a build-up of the
queue.
Effect~\ref{enm:sojourn_1over2} is a consequence of
effects~\ref{enm:custs_1over2} and~\ref{enm:custs_2over1}, as there are more
customers of Class 1 in the queue on average, their average sojourn time will
increase, as stated by Little's Theorem \cite{little61}.
Effect~\ref{enm:sojourn_2over1} however is due to upgrading customers at a
higher rate, which effectively stops lower priority customers waiting a long
time, as they will be upgraded before they end their service.
This is more pronounced (effect~\ref{enm:sojourn_pronounced}), as it is
accounting for effect~\ref{enm:sojourn_1over2} pushing the waiting times of
customers of Class 2 up, allowing more time to upgrade them before they reach
service.


\section{Experimental Validation}\label{sec:validation}


\bibliographystyle{plain}
\bibliography{refs}

\end{document}
